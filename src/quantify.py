#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ•¸ä½éŸŒæ€§é‡åŒ–æ¨¡çµ„ - å…­ç¶­åº¦éŸŒæ€§èƒ½åŠ›æ¡†æ¶
- åŸºæ–¼æ•¸ä½éŸŒæ€§ç†è«–çš„ 6 å€‹æ ¸å¿ƒèƒ½åŠ›
- æ¯å€‹èƒ½åŠ›ç”±ç¨ç«‹çš„ LLM Agent è©•åˆ†
- Absorb, Adopt, Transform, Anticipate, Rebound, Learn
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Optional
from dataclasses import dataclass, asdict
import time
import os

try:
    from openai import OpenAI
except ImportError:
    raise ImportError(
        "openai æœªå®‰è£ã€‚è«‹åŸ·è¡Œ: uv pip install openai"
    )

from .utils import setup_logger, Config
from .agent_utils import run_agent1_with_retry, parse_json_response

logger = setup_logger(__name__)

# --------------------------------
# æ¨¡å‹é…ç½®
# --------------------------------
# æ³¨æ„: æ¨¡å‹è·¯å¾‘èˆ‡åƒæ•¸ç¾åœ¨ç”± llama-server å•Ÿå‹•è…³æœ¬ (src/tools/launch_server.sh) æ§åˆ¶ã€‚
# Python ç«¯ä¸å†è² è²¬è¼‰å…¥æ¨¡å‹ï¼Œåƒ…è² è²¬èˆ‡ Server é€šè¨Šã€‚

# DEFAULT_LLM_PARAMS å·²å»¢æ£„ (ç”± Server ç«¯åƒæ•¸æ±ºå®š)

DEFAULT_GEN_PARAMS = {
    "temperature": 0.1,
    "max_tokens": 2000,
    "stop": ["}```", "\n\n\n"],
}

# é—œéµåƒæ•¸: æ§åˆ¶è¼¸å…¥ Prompt çš„é•·åº¦ï¼Œé¿å…è¶…é Server çš„ Context Window (ä¾‹å¦‚ 32k)
# å»ºè­°è¨­å®šç‚º: Server Context - Max Output - Buffer
# 32768 - 1000 - 1000 ~= 30000 (é€™è£¡è¨­å®š 28000 ä¿å®ˆä¸€é»)
MAX_TOKENS_PER_AGENT = 64000

# --------------------------------
# Agent ç« ç¯€åˆ†é…é…ç½®
# --------------------------------
# æ¯å€‹ Agent åªè®€å–èˆ‡å…¶éŸŒæ€§èƒ½åŠ›ç›¸é—œçš„ç« ç¯€
# å½ˆæ€§é…ç½®ï¼šæ ¹æ“šå„ Agent çš„å¯¦éš›éœ€æ±‚è¨­å®šä¸åŒä¸Šé™

AGENT_SECTION_MAPPING = {
    "absorb": [
        "item_1a",            # é¢¨éšªå› ç´ ï¼ˆä¾›æ‡‰éˆã€ç½å®³ã€ç³»çµ±ä¸­æ–·ï¼‰- é«˜å„ªå…ˆç´š
        "item_9a",            # Controls & Procedures - é«˜å„ªå…ˆç´š
        "item_1c",            # Cybersecurity - é«˜å„ªå…ˆç´š
        "cybersecurity",      # é¡å¤–è³‡å®‰æ®µè½ï¼ˆå¦‚æœæœ‰ï¼‰
        "information_security", # Information Securityï¼ˆå¦‚æœæœ‰ï¼‰
    ],
    "adopt": [
        "item_7",             # MD&Aï¼ˆç®¡ç†å±¤å¦‚ä½•æ‡‰å°å¸‚å ´èˆ‡è¡æ“Šï¼‰- é«˜å„ªå…ˆç´š
        "item_1",             # Businessï¼ˆç­–ç•¥èˆ‡ç‡Ÿé‹æ¨¡å¼ï¼‰- ä¸­å„ªå…ˆç´š
        "item_1a",            # éƒ¨åˆ†é¢¨éšªæ‡‰å°å…§å®¹ - ä½å„ªå…ˆç´š
    ],
    "transform": [
        "item_7",             # MD&Aï¼ˆè½‰å‹è¨ˆåŠƒï¼‰- é«˜å„ªå…ˆç´š
        "item_1",             # Businessï¼ˆå•†æ¥­æ¨¡å¼è®Šé©ï¼‰- é«˜å„ªå…ˆç´š
        "esg_sustainability", # ESG/æ·¨é›¶/æ•¸ä½è½‰å‹ - ä¸­å„ªå…ˆç´š
    ],
    "anticipate": [
        "item_1a",            # é¢¨éšªè­˜åˆ¥ã€æƒ…å¢ƒèªªæ˜ - é«˜å„ªå…ˆç´š
        "item_1c",            # è³‡å®‰é¢¨éšªç›£æ¸¬ã€è©•ä¼° - é«˜å„ªå…ˆç´š
        "cybersecurity",      # å¨è„…æƒ…å ±ã€ç›£æ§ - ä¸­å„ªå…ˆç´š
        "item_9a",            # ERMã€æŒçºŒç›£æ§ - ä¸­å„ªå…ˆç´š
    ],
    "rebound": [
        "item_1c",            # Incident response, logging, escalation - é«˜å„ªå…ˆç´š
        "cybersecurity",      # äº‹ä»¶éŸ¿æ‡‰è¨ˆåŠƒ - é«˜å„ªå…ˆç´š
        "item_9a",            # Disclosure controls, remediation - ä¸­å„ªå…ˆç´š
        "item_7",             # éå»è¡æ“Šèˆ‡æ¢å¾© - ä½å„ªå…ˆç´š
    ],
    "learn": [
        "esg_sustainability", # å“¡å·¥è¨“ç·´ã€çµ„ç¹”æ–‡åŒ– - é«˜å„ªå…ˆç´š
        "item_9a",            # Internal auditã€æ”¹é€² - é«˜å„ªå…ˆç´š
        "item_1a",            # éå»ç¶“é©—èˆ‡èª¿æ•´ - ä¸­å„ªå…ˆç´š
    ],
}

# --------------------------------
# æ•¸æ“šçµæ§‹
# --------------------------------
@dataclass
class ReviewResult:
    """è©•åˆ†å“¡å¯©æ ¸çµæœ"""
    dimension: str
    original_score: float
    # original_confidence: int # Removed/Ignored in new prompt logic, but let's keep it clean or just optional
    # New prompt structure: status, final_score, final_reasoning, audit_note
    status: str # APPROVED | CORRECTED
    final_score: float
    final_reasoning: str
    audit_note: str
    
    # Legacy fields for compatibility if needed, or remove them. 
    # The existing code expects 'is_reasonable'. Let's map 'status' to it.
    @property
    def is_reasonable(self) -> bool:
        return self.status == "APPROVED"

    @property # Compatible alias
    def suggested_adjustments(self) -> str:
        return self.audit_note

    @property # Compatible alias
    def suggested_adjustments(self) -> str:
        return self.audit_note
@dataclass
class DimensionScore:
    """å–®ä¸€éŸŒæ€§èƒ½åŠ›è©•åˆ†"""
    dimension: str  # absorb, adopt, transform, anticipate, rebound, learn
    score: float  # 0-100
    evidence: List[str]  # å¾ 10-K é€å­—å¼•ç”¨çš„è­‰æ“š
    reasoning: str  # ç‚ºä»€éº¼é€™äº›è­‰æ“šä»£è¡¨è©²èƒ½åŠ›
    review: Optional['ReviewResult'] = None  # è©•åˆ†å“¡å¯©æ ¸çµæœ

@dataclass
class ResilienceScore:
    """æ•¸ä½éŸŒæ€§è©•åˆ† - å…­ç¶­åº¦æ¡†æ¶"""
    company: str
    year: int
    cik: Optional[str] = None

    # å…­å¤§éŸŒæ€§èƒ½åŠ›
    absorb: Optional[DimensionScore] = None          # å¸æ”¶è¡æ“Šèƒ½åŠ›
    adopt: Optional[DimensionScore] = None           # é©æ‡‰è¡æ“Šèƒ½åŠ›
    transform: Optional[DimensionScore] = None       # è½‰æ›è¡æ“Šèƒ½åŠ›
    anticipate: Optional[DimensionScore] = None      # é æ¸¬èƒ½åŠ›
    rebound: Optional[DimensionScore] = None         # åå½ˆèƒ½åŠ›
    learn: Optional[DimensionScore] = None           # å­¸ç¿’èƒ½åŠ›

    # æ•´é«”åˆ†æ•¸
    overall_score: float = 0.0

    # å…ƒæ•¸æ“š
    agent_version: str = "1.0"
    processing_time: float = 0.0
    timestamp: str = ""

    def calculate_overall(self):
        """è¨ˆç®—æ•´é«”åˆ†æ•¸ï¼ˆ6å€‹ç¶­åº¦åŠ æ¬Šå¹³å‡ï¼‰"""
        # å¯ä»¥é¸æ“‡ç­‰æ¬Šé‡æˆ–åŠ æ¬Š
        weights = {
            "absorb": 1/6,
            "adopt": 1/6,
            "transform": 1/6,
            "anticipate": 1/6,
            "rebound": 1/6,
            "learn": 1/6,
        }

        total_score = 0.0
        count = 0

        for dim_name, weight in weights.items():
            dim_score = getattr(self, dim_name)
            if dim_score and dim_score.score is not None:
                total_score += dim_score.score * weight
                count += 1

        if count > 0:
            self.overall_score = round(total_score, 2)

    def to_dict(self) -> Dict:
        """è½‰æ›ç‚ºå­—å…¸"""
        return asdict(self)

# --------------------------------
# LLM åŒ…è£å™¨
# --------------------------------
# --------------------------------
# LLM åŒ…è£å™¨ (OpenAI API Compatible)
# --------------------------------
class LLMWrapper:
    """LLM åŒ…è£å™¨ (ä½¿ç”¨ OpenAI API / llama-server)"""

    def __init__(self, base_url: str = "http://localhost:8080/v1", api_key: str = "lm-studio"):
        self.base_url = base_url
        self.api_key = api_key
        self.client: Optional[OpenAI] = None
        self.model_name = "ministral-3-14b" # Placeholder, server determines actual model

    def load_model(self) -> bool:
        """
        é€£æ¥åˆ° llama-server
        æ³¨æ„ï¼šé€™è£¡ä¸å†è² è²¬è¼‰å…¥æ¨¡å‹æª”æ¡ˆï¼Œè€Œæ˜¯ç¢ºä¿ Server å¯é€£æ¥ã€‚
        æ¨¡å‹è¼‰å…¥ç”± llama-server å•Ÿå‹•åƒæ•¸æ±ºå®šã€‚
        """
        try:
            logger.info(f"æ­£åœ¨é€£æ¥ LLM Server: {self.base_url}")
            self.client = OpenAI(base_url=self.base_url, api_key=self.api_key)
            
            # æ¸¬è©¦é€£æ¥ (List models)
            models = self.client.models.list()
            logger.info(f"âœ… é€£æ¥æˆåŠŸã€‚å¯ç”¨æ¨¡å‹: {[m.id for m in models.data]}")
            return True

        except Exception as e:
            logger.error(f"ç„¡æ³•é€£æ¥ LLM Server: {e}")
            logger.error("è«‹ç¢ºä¿å·²å•Ÿå‹•: ./llama-server -m ...")
            return False

    def generate(self, prompt: str, override_params: Optional[Dict] = None) -> str:
        """ç”Ÿæˆå›æ‡‰"""
        if self.client is None:
            raise RuntimeError("å°šæœªé€£æ¥ Serverï¼Œè«‹å…ˆå‘¼å« load_model()")

        params = {**DEFAULT_GEN_PARAMS, **(override_params or {})}
        
        # ç§»é™¤ä¸æ”¯æ´çš„åƒæ•¸
        if "stop" in params and isinstance(params["stop"], list):
            # OpenAI API é€šå¸¸æ”¯æ´æœ€å¤š 4 å€‹ stop sequences
            pass
        
        # ç§»é™¤ llama-cpp ç‰¹æœ‰åƒæ•¸
        params.pop("grammar", None) 

        try:
            # ä½¿ç”¨ Completion API (llama-server æ”¯æ´ /v1/completions ç”¨æ–¼åŸå§‹è£œå…¨)
            # æˆ–è€… Chat APIã€‚é€™è£¡ Prompt æ˜¯åŸå§‹æ–‡å­—ï¼Œå»ºè­°ç”¨ completionsã€‚
            response = self.client.completions.create(
                model=self.model_name,
                prompt=prompt,
                max_tokens=params.get("max_tokens", 1000),
                temperature=params.get("temperature", 0.1),
                stop=params.get("stop", None),
                # top_p, frequency_penalty ç­‰å¯ä¾éœ€æ·»åŠ 
            )
            return response.choices[0].text
        except Exception as e:
            logger.error(f"ç”Ÿæˆå¤±æ•—: {e}")
            raise

    def reset_cache(self):
        """
        Server æ¨¡å¼ä¸‹é€šå¸¸ä¸éœ€è¦æ‰‹å‹• reset contextï¼Œ
        å› ç‚ºæ¯å€‹ request æ˜¯ç¨ç«‹çš„ (Stateless unless using context caching slots explicitly).
        llama-server æœƒè‡ªå‹•ç®¡ç† slotã€‚
        """
        pass

    def unload_model(self):
        """Server æ¨¡å¼ä¸‹ç„¡æ³•ç”± Client å¸è¼‰æ¨¡å‹"""
        pass

# --------------------------------
# å…­å€‹éŸŒæ€§èƒ½åŠ›çš„ System Prompts
# --------------------------------

def load_prompt(name: str) -> str:
    """å¾ src/prompts è¼‰å…¥ System Prompt"""
    try:
        prompt_path = Config.PROJECT_ROOT / "src" / "prompts" / f"{name}.txt"
        if not prompt_path.exists():
            logger.error(f"Prompt æª”æ¡ˆä¸å­˜åœ¨: {prompt_path}")
            return ""
        return prompt_path.read_text(encoding="utf-8").strip()
    except Exception as e:
        logger.error(f"è¼‰å…¥ Prompt {name} å¤±æ•—: {e}")
        return ""

SYSTEM_PROMPT_ABSORB = load_prompt("absorb")

SYSTEM_PROMPT_ADOPT = load_prompt("adopt")

SYSTEM_PROMPT_TRANSFORM = load_prompt("transform")

SYSTEM_PROMPT_ANTICIPATE = load_prompt("anticipate")

SYSTEM_PROMPT_REBOUND = load_prompt("rebound")

SYSTEM_PROMPT_LEARN = load_prompt("learn")
SYSTEM_PROMPT_AUDITOR = load_prompt("Auditor") # Load the new Auditor prompt

# --------------------------------
# Helper Functions
# --------------------------------

def load_cleaned_report(company: str, year: int) -> Optional[Dict[str, str]]:
    """è¼‰å…¥å·²æ¸…ç†çš„ 10-K å ±å‘Š"""
    year_short = str(year)[-2:]

    patterns = [
        f"{company.upper()}_10-K_*-{year_short}-*_primary-document.json",
        f"{company}_10-K_*-{year_short}-*_primary-document.json",
    ]

    for pattern in patterns:
        matches = list(Config.CLEANED_DATA_DIR.glob(pattern))
        if matches:
            json_path = sorted(matches)[-1]
            logger.info(f"æ‰¾åˆ°å ±å‘Š: {json_path.name}")

            try:
                data = json.loads(json_path.read_text(encoding="utf-8"))
                return data
            except Exception as e:
                logger.error(f"è®€å–å ±å‘Šå¤±æ•— {json_path}: {e}")
                return None

    logger.warning(f"æ‰¾ä¸åˆ°å ±å‘Š: {company} {year}")
    return None

def prepare_report_context(report_data: Dict[str, str]) -> str:
    """æº–å‚™å ±å‘Šä¸Šä¸‹æ–‡ï¼ˆå·²æ£„ç”¨ - è«‹ä½¿ç”¨ extract_relevant_sectionsï¼‰"""
    sections = []

    for key, value in report_data.items():
        if key not in ["source", "company", "year", "cik"] and value:
            sections.append(f"## {key.upper()}\n{value}\n")

    return "\n".join(sections)

def extract_relevant_sections(
    report_data: Dict[str, str],
    agent_name: str,
    max_tokens: Optional[int] = None
) -> str:
    """
    ç‚ºç‰¹å®š Agent æå–ç›¸é—œç« ç¯€

    Args:
        report_data: å®Œæ•´å ±å‘Šæ•¸æ“šï¼ˆå­—å…¸ï¼‰
        agent_name: Agent åç¨± (absorb/adopt/transform/anticipate/rebound/learn)
        max_tokens: æœ€å¤§ token æ•¸é™åˆ¶ï¼ˆNone å‰‡ä½¿ç”¨è©² Agent çš„é è¨­å€¼ï¼‰

    Returns:
        çµ„åˆå¾Œçš„ç›¸é—œç« ç¯€æ–‡æœ¬ï¼ˆæ§åˆ¶åœ¨ max_tokens å…§ï¼‰
    """
    # ç²å–è©² Agent çš„ç« ç¯€åˆ—è¡¨
    sections = AGENT_SECTION_MAPPING.get(agent_name, [])

    # ç²å–è©² Agent çš„ token é™åˆ¶ï¼ˆæ”¯æ´å­—å…¸é…ç½®ï¼‰
    if max_tokens is None:
        if isinstance(MAX_TOKENS_PER_AGENT, dict):
            max_tokens = MAX_TOKENS_PER_AGENT.get(agent_name, DEFAULT_MAX_TOKENS)
        else:
            max_tokens = MAX_TOKENS_PER_AGENT

    if not sections:
        logger.warning(f"æœªæ‰¾åˆ° {agent_name} çš„ç« ç¯€æ˜ å°„ï¼Œè¿”å›ç©ºå­—ä¸²")
        return ""

    context_parts = []
    total_chars = 0
    max_chars = max_tokens * 4  # ç²—ä¼° 1 token â‰ˆ 4 chars

    for section_key in sections:
        # æª¢æŸ¥ç« ç¯€æ˜¯å¦å­˜åœ¨ä¸”éç©º
        if section_key in report_data and report_data[section_key]:
            section_text = report_data[section_key]
            section_header = f"\n\n=== {section_key.upper()} ===\n\n"

            # æª¢æŸ¥æ˜¯å¦è¶…å‡ºé™åˆ¶
            potential_total = total_chars + len(section_header) + len(section_text)

            if potential_total > max_chars:
                # è¨ˆç®—å‰©é¤˜å¯ç”¨ç©ºé–“
                remaining_space = max_chars - total_chars - len(section_header)

                if remaining_space > 1000:  # è‡³å°‘ä¿ç•™ 1000 å­—å…ƒ
                    # æˆªæ–·ç« ç¯€
                    section_text = section_text[:remaining_space] + "\n\n[...å…§å®¹å·²æˆªæ–·]"
                    context_parts.append(section_header + section_text)
                    total_chars += len(section_header) + len(section_text)
                    logger.info(f"  {section_key}: å·²æˆªæ–·è‡³ {remaining_space} å­—å…ƒ")
                else:
                    # ç©ºé–“ä¸è¶³ï¼Œåœæ­¢æ·»åŠ 
                    logger.info(f"  {section_key}: ç©ºé–“ä¸è¶³ï¼Œè·³é")
                break

            # æ·»åŠ å®Œæ•´ç« ç¯€
            context_parts.append(section_header + section_text)
            total_chars += len(section_header) + len(section_text)
            logger.info(f"  {section_key}: {len(section_text)} å­—å…ƒ")

    # è¨˜éŒ„ç¸½è¨ˆ
    total_tokens_approx = total_chars / 4
    logger.info(f"âœ… {agent_name} ä¸Šä¸‹æ–‡: {total_chars:,} å­—å…ƒ (~{total_tokens_approx:.0f} tokens)")

    return "".join(context_parts)

def parse_json_response(response: str) -> Optional[Dict]:
    """è§£æ JSON å›æ‡‰"""
    # ç›´æ¥è§£æ
    try:
        return json.loads(response)
    except:
        pass

    # æå– JSON code block
    json_match = re.search(r'```json\s*(.*?)```', response, re.DOTALL)
    if json_match:
        try:
            return json.loads(json_match.group(1))
        except:
            pass

    # æå– {...}
    json_match = re.search(r'\\{.*\\}', response, re.DOTALL)
    if json_match:
        try:
            return json.loads(json_match.group(0))
        except:
            pass


# --------------------------------
# JSON Schema / Grammar (Disabled for OpenAI API)
# --------------------------------
# OpenAI API does not support GBNF grammars directly in the same way.
# We will rely on prompt engineering and json_repair.

def get_agent1_grammar():
    """Grammar disabled for server mode"""
    return None

def get_auditor_grammar():
    """Grammar disabled for server mode"""
    return None

# --------------------------------
# å…­å€‹ç¨ç«‹çš„ Agent è©•åˆ†å‡½æ•¸
# --------------------------------

def agent_absorb(
    llm_wrapper: LLMWrapper,
    company: str,
    year: int,
    report_data: Dict[str, str]
) -> Optional[DimensionScore]:
    """Absorb Agent - è©•ä¼°å¸æ”¶è¡æ“Šèƒ½åŠ›ï¼ˆåªè®€å–ç›¸é—œç« ç¯€ï¼‰"""
    logger.info(f"=== Absorb Agent è©•åˆ†: {company} ({year}) ===")

    # æå–ç›¸é—œç« ç¯€ï¼šitem_1a, item_9a, item_1c, cybersecurity, information_security
    relevant_context = extract_relevant_sections(report_data, "absorb")

    if not relevant_context:
        logger.warning("Absorb Agent: ç„¡ç›¸é—œç« ç¯€ï¼Œè¿”å› None")
        return None

    prompt = f"""{SYSTEM_PROMPT_ABSORB}

# Company: {company} ({year})

## 10-K Report Content (Relevant Sections):

{relevant_context}

---

Now evaluate the ABSORB capability and output JSON.
IMPORTANT: Provide ONLY ONE sentence of evidence and ONLY ONE sentence of reasoning.
<|end|><|start|>assistant<|channel|>analysis<|message|><|end|><|start|>assistant<|channel|>
"""

    result = run_agent1_with_retry(llm_wrapper, prompt, relevant_context, "absorb", grammar=get_agent1_grammar())
    
    if not result:
        return None

    return DimensionScore(
        dimension="absorb",
        score=float(result.get("score", 0)),
        evidence=result.get("evidence", []),
        reasoning=result.get("reasoning", "")
    )

def agent_adopt(llm_wrapper: LLMWrapper, company: str, year: int, report_data: Dict[str, str]) -> Optional[DimensionScore]:
    """Adopt Agent - è©•ä¼°é©æ‡‰è¡æ“Šèƒ½åŠ›"""
    logger.info(f"=== Adopt Agent è©•åˆ†: {company} ({year}) ===")

    # æå–ç›¸é—œç« ç¯€ï¼šitem_7, item_1, item_1a
    relevant_context = extract_relevant_sections(report_data, "adopt")

    if not relevant_context:
        logger.warning("Adopt Agent: ç„¡ç›¸é—œç« ç¯€ï¼Œè¿”å› None")
        return None

    prompt = f"""{SYSTEM_PROMPT_ADOPT}

# Company: {company} ({year})

## 10-K Report Content (Relevant Sections):

{relevant_context}

---

Now evaluate the ADOPT capability and output JSON.
IMPORTANT: Provide ONLY ONE sentence of evidence and ONLY ONE sentence of reasoning.
<|end|><|start|>assistant<|channel|>analysis<|message|><|end|><|start|>assistant<|channel|>
"""
    result = run_agent1_with_retry(llm_wrapper, prompt, relevant_context, "adopt", grammar=get_agent1_grammar())
    if not result: return None

    return DimensionScore(
        dimension="adopt",
        score=float(result.get("score", 0)),
        evidence=result.get("evidence", []),
        reasoning=result.get("reasoning", "")
    )

def agent_transform(llm_wrapper: LLMWrapper, company: str, year: int, report_data: Dict[str, str]) -> Optional[DimensionScore]:
    """Transform Agent - è©•ä¼°è½‰æ›è¡æ“Šèƒ½åŠ›"""
    logger.info(f"=== Transform Agent è©•åˆ†: {company} ({year}) ===")

    # æå–ç›¸é—œç« ç¯€ï¼šitem_7, item_1, esg_sustainability
    relevant_context = extract_relevant_sections(report_data, "transform")

    if not relevant_context:
        logger.warning("Transform Agent: ç„¡ç›¸é—œç« ç¯€ï¼Œè¿”å› None")
        return None

    prompt = f"""{SYSTEM_PROMPT_TRANSFORM}

# Company: {company} ({year})

## 10-K Report Content (Relevant Sections):

{relevant_context}

---

Now evaluate the TRANSFORM capability and output JSON.
IMPORTANT: Provide ONLY ONE sentence of evidence and ONLY ONE sentence of reasoning.
<|end|><|start|>assistant<|channel|>analysis<|message|><|end|><|start|>assistant<|channel|>
"""
    result = run_agent1_with_retry(llm_wrapper, prompt, relevant_context, "transform", grammar=get_agent1_grammar())
    if not result: return None

    return DimensionScore(
        dimension="transform",
        score=float(result.get("score", 0)),
        evidence=result.get("evidence", []),
        reasoning=result.get("reasoning", "")
    )

def agent_anticipate(llm_wrapper: LLMWrapper, company: str, year: int, report_data: Dict[str, str]) -> Optional[DimensionScore]:
    """Anticipate Agent - è©•ä¼°é æ¸¬èƒ½åŠ›"""
    logger.info(f"=== Anticipate Agent è©•åˆ†: {company} ({year}) ===")

    # æå–ç›¸é—œç« ç¯€ï¼šitem_1a, item_1c, cybersecurity, item_9a
    relevant_context = extract_relevant_sections(report_data, "anticipate")

    if not relevant_context:
        logger.warning("Anticipate Agent: ç„¡ç›¸é—œç« ç¯€ï¼Œè¿”å› None")
        return None

    prompt = f"""{SYSTEM_PROMPT_ANTICIPATE}

# Company: {company} ({year})

## 10-K Report Content (Relevant Sections):

{relevant_context}

---

Now evaluate the ANTICIPATE capability and output JSON.
IMPORTANT: Provide ONLY ONE sentence of evidence and ONLY ONE sentence of reasoning.
<|end|><|start|>assistant<|channel|>analysis<|message|><|end|><|start|>assistant<|channel|>
"""
    result = run_agent1_with_retry(llm_wrapper, prompt, relevant_context, "anticipate", grammar=get_agent1_grammar())
    if not result: return None

    return DimensionScore(
        dimension="anticipate",
        score=float(result.get("score", 0)),
        evidence=result.get("evidence", []),
        reasoning=result.get("reasoning", "")
    )

def agent_rebound(llm_wrapper: LLMWrapper, company: str, year: int, report_data: Dict[str, str]) -> Optional[DimensionScore]:
    """Rebound Agent - è©•ä¼°åå½ˆèƒ½åŠ›"""
    logger.info(f"=== Rebound Agent è©•åˆ†: {company} ({year}) ===")

    # æå–ç›¸é—œç« ç¯€ï¼šitem_1c, cybersecurity, item_9a, item_7
    relevant_context = extract_relevant_sections(report_data, "rebound")

    if not relevant_context:
        logger.warning("Rebound Agent: ç„¡ç›¸é—œç« ç¯€ï¼Œè¿”å› None")
        return None

    prompt = f"""{SYSTEM_PROMPT_REBOUND}

# Company: {company} ({year})

## 10-K Report Content (Relevant Sections):

{relevant_context}

---

Now evaluate the REBOUND capability and output JSON.
IMPORTANT: Provide ONLY ONE sentence of evidence and ONLY ONE sentence of reasoning.
<|end|><|start|>assistant<|channel|>analysis<|message|><|end|><|start|>assistant<|channel|>
"""
    result = run_agent1_with_retry(llm_wrapper, prompt, relevant_context, "rebound", grammar=get_agent1_grammar())
    if not result: return None

    return DimensionScore(
        dimension="rebound",
        score=float(result.get("score", 0)),
        evidence=result.get("evidence", []),
        reasoning=result.get("reasoning", "")
    )

def agent_learn(llm_wrapper: LLMWrapper, company: str, year: int, report_data: Dict[str, str]) -> Optional[DimensionScore]:
    """Learn Agent - è©•ä¼°å­¸ç¿’èƒ½åŠ›"""
    logger.info(f"=== Learn Agent è©•åˆ†: {company} ({year}) ===")

    # æå–ç›¸é—œç« ç¯€ï¼šesg_sustainability, item_9a, item_1a
    relevant_context = extract_relevant_sections(report_data, "learn")

    if not relevant_context:
        logger.warning("Learn Agent: ç„¡ç›¸é—œç« ç¯€ï¼Œè¿”å› None")
        return None

    prompt = f"""{SYSTEM_PROMPT_LEARN}

# Company: {company} ({year})

## 10-K Report Content (Relevant Sections):

{relevant_context}

---

Now evaluate the LEARN capability and output JSON.
IMPORTANT: Provide ONLY ONE sentence of evidence and ONLY ONE sentence of reasoning.
<|end|><|start|>assistant<|channel|>analysis<|message|><|end|><|start|>assistant<|channel|>
"""

    result = run_agent1_with_retry(llm_wrapper, prompt, relevant_context, "learn", grammar=get_agent1_grammar())
    if not result: return None

    return DimensionScore(
        dimension="learn",
        score=float(result.get("score", 0)),
        evidence=result.get("evidence", []),
        reasoning=result.get("reasoning", "")
    )

# --------------------------------
# ä¸»è©•åˆ†å‡½æ•¸
# --------------------------------

def score_resilience(
    llm_wrapper: LLMWrapper,
    company: str,
    year: int,
    report_data: Dict[str, str],
    enable_reviewer: bool = True
) -> Optional[ResilienceScore]:
    """
    ä½¿ç”¨ 6 å€‹ç¨ç«‹ Agent è©•ä¼°æ•¸ä½éŸŒæ€§

    Args:
        llm_wrapper: LLM å¯¦ä¾‹ï¼ˆå·²è¼‰å…¥ï¼‰
        company: å…¬å¸åç¨±
        year: å¹´ä»½
        report_data: å ±å‘Šæ•¸æ“š

    Returns:
        ResilienceScore ç‰©ä»¶
    """
    logger.info(f"=== é–‹å§‹è©•åˆ†: {company} ({year}) ===")
    start_time = time.time()

    # åˆå§‹åŒ–çµæœ
    score_obj = ResilienceScore(
        company=company,
        year=year,
        cik=report_data.get("cik"),
        agent_version="3.0",  # å–® Agent åŸ·è¡Œæ¨¡å¼ï¼ˆå®Œå…¨éš”é›¢ï¼Œç„¡æˆªæ–·ï¼‰
        timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
    )

    # å–® Agent åŸ·è¡Œæ¨¡å¼ï¼ˆå„ªåŒ–ç‰ˆï¼‰ï¼šä¸€æ¬¡æ€§è¼‰å…¥æ¨¡å‹ï¼Œä¸­é–“ä½¿ç”¨ reset_cache() æ¸…ç©º Context
    # å„ªé»ï¼š
    # 1. æ¸›å°‘ 6 æ¬¡æ¨¡å‹è¼‰å…¥/å¸è¼‰ IO æ™‚é–“ï¼ˆç¯€çœ ~10sï¼‰
    # 2. reset_cache() ç¬é–“æ¸…ç©º KV cacheï¼Œç¢ºä¿ Agent é–“ Context éš”é›¢
    # 3. ä¿æŒå–® Agent å…§å­˜å„ªå‹¢ (Context ä¸æœƒç´¯ç©)

    try:
        # 1. è¼‰å…¥æ¨¡å‹ï¼ˆä¸€æ¬¡æ€§ï¼‰
        if not llm_wrapper.load_model():
            logger.error("âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œçµ‚æ­¢è©•åˆ†")
            return score_obj

        agent_functions = [
            ("absorb", agent_absorb),
            ("adopt", agent_adopt),
            ("transform", agent_transform),
            ("anticipate", agent_anticipate),
            ("rebound", agent_rebound),
            ("learn", agent_learn),
        ]

        for agent_name, agent_func in agent_functions:
            logger.info(f"ğŸ”„ åŸ·è¡Œ {agent_name.upper()} Agent")

            # 2. åŸ·è¡Œ Agent
            try:
                result = agent_func(llm_wrapper, company, year, report_data)
                setattr(score_obj, agent_name, result)
            except Exception as e:
                logger.error(f"âŒ {agent_name} Agent åŸ·è¡Œå¤±æ•—: {e}")
                setattr(score_obj, agent_name, None)

            # 3. æ¸…ç©º Cache (Critical for isolation)
            llm_wrapper.reset_cache()
            
            # å¼·åˆ¶å›æ”¶ Python GC (Selection: Optional safety)
            # import gc; gc.collect()

        # è¨ˆç®—æ•´é«”åˆ†æ•¸
        score_obj.calculate_overall()

        # 4. åŸ·è¡Œè©•åˆ†å“¡å¯©æ ¸ (Reviewer Agent)
        if enable_reviewer:
            logger.info("ğŸ”„ åŸ·è¡Œ Reviewer Agentï¼ˆå¯©æ ¸æ‰€æœ‰è©•åˆ†ï¼‰")
            try:
                reviews = review_all_scores(llm_wrapper, score_obj)
                
                # å°‡å¯©æ ¸çµæœå¡«å› score_obj
                for dim_name, review_result in reviews.items():
                    dim_score = getattr(score_obj, dim_name)
                    if dim_score:
                        dim_score.review = review_result
            except Exception as e:
                logger.error(f"âŒ Reviewer Agent åŸ·è¡Œå¤±æ•—: {e}")
        else:
            logger.info("â„¹ï¸ è·³é Reviewer Agent (ä½¿ç”¨è€…è¨­å®š)")

    finally:
        # 5. ç¢ºä¿æœ€å¾Œå¸è¼‰æ¨¡å‹
        llm_wrapper.unload_model()

    # è¨˜éŒ„è™•ç†æ™‚é–“
    score_obj.processing_time = time.time() - start_time

    logger.info(f"âœ… è©•åˆ†å®Œæˆ: {score_obj.overall_score:.1f}/100 (è€—æ™‚ {score_obj.processing_time:.1f}s)")

    return score_obj

def save_score_to_file(score: ResilienceScore, output_dir: Optional[Path] = None) -> Path:
    """å„²å­˜è©•åˆ†çµæœ"""
    out_dir = output_dir or Config.SCORES_DIR
    out_dir.mkdir(parents=True, exist_ok=True)

    filename = f"{score.company}_{score.year}_score.json"
    output_path = out_dir / filename

    output_path.write_text(
        json.dumps(score.to_dict(), ensure_ascii=False, indent=2),
        encoding="utf-8"
    )

    logger.info(f"è©•åˆ†å·²å„²å­˜: {output_path}")
    return output_path

# --------------------------------
# æ¸¬è©¦å‡½æ•¸
# --------------------------------


# --------------------------------
# è©•åˆ†å“¡ Agent (Reviewer)
# --------------------------------



def review_all_scores(
    llm_wrapper: LLMWrapper,
    score: ResilienceScore,
    # report_context: str # Unused in new prompt constraint
) -> Dict[str, ReviewResult]:
    """å¯©æ ¸æ‰€æœ‰ç¶­åº¦çš„è©•åˆ† (Batch Mode)"""
    logger.info("\n=== é–‹å§‹è©•åˆ†å“¡å¯©æ ¸ (Lead Auditor Batch) ===")
    
    # 1. çµ„å»º Input JSON
    # Map lowercase dimension names to CAPS keys required by Lead Auditor
    # Keys: ABSORB, ADAPT, TRANSFORM, ANTICIPATE, REBOUND, LEARN
    # Note: 'adopt' in code corresponds to 'ADAPT' in standard/prompt? 
    # Let's check the prompt instructions: "ADAPT" is one of the keys.
    # Code uses 'adopt' for variable/capability name. I should safely map 'adopt' -> 'ADAPT'.
    
    mapping = {
        "absorb": "ABSORB",
        "adopt": "ADAPT",
        "transform": "TRANSFORM",
        "anticipate": "ANTICIPATE",
        "rebound": "REBOUND",
        "learn": "LEARN"
    }
    
    input_data = {}
    
    for dim_lower, dim_upper in mapping.items():
        dim_score = getattr(score, dim_lower)
        if dim_score:
            input_data[dim_upper] = {
                "evidence": dim_score.evidence,
                "reasoning": dim_score.reasoning,
                "score": int(dim_score.score)
            }
        else:
            # Handle missing scores gracefully? Or skip?
            # Auditor prompt implies it receives all 6.
            # Let's provide dummy entry if missing so Auditor can force it to 0
            input_data[dim_upper] = {
                "evidence": [],
                "reasoning": "Scoring failed or missing",
                "score": 0
            }

    input_json_str = json.dumps(input_data, indent=2, ensure_ascii=False)

    # 2. Construct Prompt
    prompt = f"""{SYSTEM_PROMPT_AUDITOR}

# INPUT DATA (Junior Agent Reports):

{input_json_str}

---

Now perform the Logic & Consistency Check for all 6 capabilities and output the single JSON object.
IMPORTANT: Provide ONLY ONE sentence for 'audit_note' and 'final_reasoning'.
<|end|><|start|>assistant<|channel|>analysis<|message|><|end|><|start|>assistant<|channel|>
"""

    # 3. Call LLM
    try:
        response = llm_wrapper.generate(
            prompt, 
            override_params={
                "temperature": 0.1, 
                "max_tokens": 2000, # Increased for larger output
                "grammar": get_auditor_grammar()
            }
        )
        
        # 4. Parse Result
        result_json = parse_json_response(response)
        if not result_json:
            logger.error("âŒ Lead Auditor JSON parsing failed")
            return {}

        # 5. Convert to ReviewResult objects
        reviews = {}
        # Map back UPPER -> lower
        reverse_mapping = {v: k for k, v in mapping.items()}
        
        for key_upper, audit_data in result_json.items():
            key_lower = reverse_mapping.get(key_upper)
            if not key_lower:
                continue
                
            reviews[key_lower] = ReviewResult(
                dimension=key_lower,
                original_score=input_data[key_upper]["score"],
                status=audit_data.get("status", "UNKNOWN"),
                final_score=float(audit_data.get("final_score", 0)),
                final_reasoning=audit_data.get("final_reasoning", ""),
                audit_note=audit_data.get("audit_note", "")
            )
            
            logger.info(f"  {key_upper}: {audit_data.get('status')} -> {audit_data.get('final_score')} (Note: {audit_data.get('audit_note')})")

        return reviews

    except Exception as e:
        logger.error(f"Lead Auditor execution failed: {e}")
        return {}


def test_scoring():
    """æ¸¬è©¦è©•åˆ†ç³»çµ±"""
    company = "AAPL"
    year = 2024

    logger.info("=== æ¸¬è©¦å…­ç¶­åº¦éŸŒæ€§è©•åˆ† ===")

    # è¼‰å…¥å ±å‘Š
    report_data = load_cleaned_report(company, year)
    if not report_data:
        logger.error("å ±å‘Šè¼‰å…¥å¤±æ•—")
        return False

    # åˆå§‹åŒ– LLM wrapperï¼ˆä¸è¼‰å…¥æ¨¡å‹ï¼Œç”± score_resilience å…§éƒ¨çš„æ¯å€‹ Agent ç¨ç«‹è¼‰å…¥ï¼‰
    wrapper = LLMWrapper()

    try:
        # åŸ·è¡Œè©•åˆ†ï¼ˆå–® Agent æ¨¡å¼ï¼šæ¯å€‹ Agent ç¨ç«‹è¼‰å…¥/å¸è¼‰æ¨¡å‹ï¼‰
        score = score_resilience(wrapper, company, year, report_data)

        if score:
            logger.info("\n=== è©•åˆ†çµæœ ===")
            logger.info(f"å…¬å¸: {score.company} ({score.year})")
            logger.info(f"æ•´é«”åˆ†æ•¸: {score.overall_score:.1f}/100")
            # logger.info(f"æ•´é«”ä¿¡å¿ƒ: {score.overall_confidence:.2f} (å¹³å‡å€¼: 0=ç¼ºä¹, 1=é©åº¦, 2=å¼·çƒˆ)")

            logger.info("\nå…­ç¶­åº¦åˆ†æ•¸:")
            for dim_name in ["absorb", "adopt", "transform", "anticipate", "rebound", "learn"]:
                dim_score = getattr(score, dim_name)
                if dim_score:
                    
                    review_msg = ""
                    if dim_score.review:
                        status_icon = "âœ…" if dim_score.review.status == "APPROVED" else "âš ï¸"
                        review_msg = f" | å¯©æ ¸: {status_icon}"
                        if dim_score.review.status == "CORRECTED":
                            review_msg += f" å»ºè­°: {dim_score.review.audit_note[:30]}..."

                    logger.info(f"  - {dim_name.capitalize()}: {dim_score.score}{review_msg}")
                else:
                    logger.info(f"  - {dim_name.capitalize()}: N/A (è©•åˆ†å¤±æ•—)")

            # å„²å­˜çµæœ
            output_path = save_score_to_file(score)
            logger.info(f"\nçµæœå·²å„²å­˜è‡³: {output_path}")

            logger.info("âœ… è©•åˆ†æ¸¬è©¦æˆåŠŸ")
            return True
        else:
            logger.error("è©•åˆ†å¤±æ•—")
            return False

    finally:
        wrapper.unload_model()

if __name__ == "__main__":
    test_scoring()

# --------------------------------
# å‘å¾Œç›¸å®¹å±¤ (Backward Compatibility)
# --------------------------------
def agent1_score_report(
    llm_wrapper: LLMWrapper,
    company: str,
    year: int,
    report_data: Dict[str, str],
    enable_reviewer: bool = True
) -> Optional[ResilienceScore]:
    """
    å‘å¾Œç›¸å®¹å‡½æ•¸ - å°æ‡‰ v1.0 çš„ agent1_score_report
    å¯¦éš›èª¿ç”¨ score_resilience
    """
    return score_resilience(llm_wrapper, company, year, report_data, enable_reviewer=enable_reviewer)

